{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b84a3ab-ff3d-4a67-b351-8b01c5c81494",
   "metadata": {},
   "source": [
    "## Segmenting Mitochondria Using Thresholding Methods\n",
    "\n",
    "In this section, we explore different thresholding techniques to segment mitochondria from fluorescence microscopy images.\n",
    "\n",
    "We will:\n",
    "- Read a single-channel mitochondrial image.\n",
    "- Apply a median filter to reduce noise.\n",
    "- Apply a thresholding method (Otsu, Yen, Li, etc.) \n",
    "- Visualize:\n",
    "  - The original image\n",
    "  - The filtered (preprocessed) image\n",
    "  - The binary mask (thresholded)\n",
    "  - The overlay of the segmentation mask on the original image\n",
    "\n",
    "You can try different methods by changing the `method` parameter in the code cell. Try changing `method = \"otsu\"` to `\"yen\"` or `\"li\"` to see how different thresholding methods affect the segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5fbcd-2755-4f89-87b0-bcb70c476cd9",
   "metadata": {},
   "source": [
    "## Setup for Google Colab\n",
    "\n",
    "If you're running this notebook in Google Colab, run the cell below to install the required Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465ad5d-bac6-486b-b955-51bd058a9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imageio[ffmpeg] scikit-image matplotlib cellpose stardist csbdeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aca20f-4b2b-4369-aea8-6230129ea336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from imageio import imwrite\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import disk, remove_small_objects\n",
    "from skimage.filters.rank import median\n",
    "from skimage.filters import threshold_otsu, threshold_yen, threshold_li, threshold_triangle, threshold_mean\n",
    "from skimage.exposure import equalize_adapthist, rescale_intensity\n",
    "from skimage.segmentation import mark_boundaries, find_boundaries\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import label\n",
    "from pathlib import Path\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "from cellpose import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee326d5-8d11-4d41-af9f-b3389c732740",
   "metadata": {},
   "source": [
    "## Connect Google Drive to Colab\n",
    "\n",
    "Run the code cell below to mount your Google Drive in Colab.\n",
    "\n",
    "#### Instructions:\n",
    "1. Run the cell.\n",
    "2. Click on the URL that appears.\n",
    "3. Sign in with your Google account.\n",
    "4. Copy the authorization code provided.\n",
    "5. Paste it into the text box in Colab and press Enter.\n",
    "6. Click on the **\"Files\"** tab on the left panel.\n",
    "7. Refresh the panel if needed, you should now see a folder called `drive/` representing your Google Drive.\n",
    "\n",
    "This allows you to access any files you've uploaded to Google Drive directly from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180f798d-d8aa-43df-98da-7f33d8db8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa9563-5327-4691-94a5-08f10789ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_mito_image(path):\n",
    "    img = imageio.imread(path)#.astype(np.uint8)\n",
    "    \n",
    "    img = rescale_intensity(img)\n",
    "    img = median(img, disk(2))\n",
    "    img = (equalize_adapthist(img, clip_limit=0.01) * 255).astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "def apply_global_threshold(img, method=\"otsu\", min_size=0):\n",
    "    # All supported methods in a dictionary\n",
    "    methods = {\n",
    "        \"otsu\": threshold_otsu,\n",
    "        \"yen\": threshold_yen,\n",
    "        \"li\": threshold_li,\n",
    "        \"triangle\": threshold_triangle,\n",
    "        \"mean\": threshold_mean\n",
    "    }\n",
    "\n",
    "    if method not in methods:\n",
    "        raise ValueError(f\"Unsupported thresholding method: {method}\")\n",
    "\n",
    "    thresh_val = methods[method](img)\n",
    "    binary = img > thresh_val\n",
    "\n",
    "    if min_size > 0:\n",
    "        binary = remove_small_objects(binary, min_size=min_size)\n",
    "\n",
    "    return binary.astype(np.uint8)\n",
    "\n",
    "def plot_segmentation(original, preprocessed, mask, method_name):\n",
    "    boundary_overlay = mark_boundaries(preprocessed, mask, color=(1, 0, 0))  # red boundaries\n",
    "\n",
    "    #fig, axs = plt.subplots(1, 4, figsize=(18, 5))\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axs = axs.ravel()  # Flatten to 1D for easier indexing\n",
    "\n",
    "    axs[0].imshow(original, cmap=\"gray\")\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "\n",
    "    axs[1].imshow(preprocessed, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axs[1].set_title(\"Preprocessed\")\n",
    "\n",
    "    axs[2].imshow(mask, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axs[2].set_title(f\"Binary Mask ({method_name})\")\n",
    "\n",
    "    axs[3].imshow(boundary_overlay)\n",
    "    axs[3].set_title(\"Overlay (Boundaries)\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac3f61-bae6-4d83-8f3c-d09535bded80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Try it ===\n",
    "image_path = Path(\"/Users/giselemiranda/MirandaLab/Collaborations/Marcelo-Unicamp/workshop-unicamp/data_day2-3/JUMP-CP_mini/Brefeldin-A-like/Orig/Mito/CP1-SC1-08_P06_T0001F001L01A01Z01C02.tif\")  # ‚Üê update this\n",
    "\n",
    "original = imageio.imread(image_path)\n",
    "preprocessed = load_and_preprocess_mito_image(image_path)\n",
    "binary_mask = apply_global_threshold(preprocessed,\"yen\",100)\n",
    "plot_segmentation(original, preprocessed, binary_mask,\"otsu\")\n",
    "\n",
    "# optional\n",
    "# imwrite(out_path, (binary_mask.astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e8242-e04b-41d5-81f5-9c6ec3617c48",
   "metadata": {},
   "source": [
    "## Segmenting Nuclei with Thresholding and StarDist\n",
    "\n",
    "In this section, we demonstrate two approaches for segmenting nuclei:\n",
    "\n",
    "1. **Otsu Thresholding**: A traditional global thresholding method that separates foreground and background based on histogram intensity peaks. This is combined with `remove_small_objects` to clean up the result.\n",
    "2. **StarDist**: A deep learning model that detects and segments star-convex shapes, particularly effective for nuclei in fluorescence images.\n",
    "\n",
    "We will:\n",
    "- Load and preprocess a nuclei (DNA) image.\n",
    "- Segment the nuclei using Otsu thresholding and label the connected components.\n",
    "- Segment the same image using StarDist.\n",
    "- Visualize and compare both segmentation outputs.\n",
    "\n",
    "You can use this comparison to evaluate the performance trade-offs between classical and deep learning-based methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8283b-66e5-46cb-be88-29982ae17525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Parameters ===\n",
    "image_path = Path(\"../data_day2-3/JUMP-CP_mini/Brefeldin-A-like/Orig/DNA/CP1-SC1-08_P06_T0001F001L01A01Z01C01.tif\") \n",
    "method = \"otsu\"\n",
    "min_size = 50\n",
    "\n",
    "# === Load & preprocess image ===\n",
    "preprocessed = load_and_preprocess_mito_image(image_path)  # Reuse same function\n",
    "\n",
    "# === Segment with global thresholding (Otsu) ===\n",
    "binary_thresh = apply_global_threshold(preprocessed, method=method, min_size=min_size)\n",
    "labeled_thresh = label(binary_thresh)\n",
    "\n",
    "# === Segment with StarDist ===\n",
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")  # DNA-style data\n",
    "stardist_labels, _ = model.predict_instances(normalize(preprocessed))\n",
    "\n",
    "# === Plotting ===\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axs = axs.ravel()  # Flatten to 1D for easier indexing\n",
    "\n",
    "axs[0].imshow(preprocessed, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0].set_title(\"Preprocessed Image\")\n",
    "\n",
    "axs[1].imshow(binary_thresh, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axs[1].set_title(\"Binary Mask (Otsu)\")\n",
    "\n",
    "axs[2].imshow(labeled_thresh, cmap=\"nipy_spectral\")\n",
    "axs[2].set_title(\"Labeled Nuclei (Otsu)\")\n",
    "\n",
    "axs[3].imshow(stardist_labels, cmap=\"nipy_spectral\")\n",
    "axs[3].set_title(\"Segmented Nuclei (StarDist)\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d448af-a3a6-4d63-9a59-a4366d64256d",
   "metadata": {},
   "source": [
    "### üß† Exercise: Counting Segmented Objects\n",
    "\n",
    "Can you implement a piece of code that **counts the number of segmented nuclei** in both outputs?\n",
    "\n",
    "You should count:\n",
    "- The number of labeled objects in the Otsu thresholded result\n",
    "- The number of labeled objects in the StarDist result\n",
    "\n",
    "---\n",
    "\n",
    "#### üí° Hints:\n",
    "- The function [`skimage.measure.label`](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.label) assigns a unique ID to each connected region in a binary image.\n",
    "- The output of `label()` can be analyzed with `np.unique()` or `regionprops_table()` to count labels.\n",
    "- Make sure to **exclude label `0`** (the background) when counting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01888275-a691-47d9-adca-7a5eecc2b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426fa1b-e514-43ed-9151-ad74a770ac96",
   "metadata": {},
   "source": [
    "## Cell Segmentation with Cellpose (Cyto3)\n",
    "\n",
    "In this section, we explore how the Cellpose model performs segmentation of whole cells using the **Cyto3 model**.\n",
    "\n",
    "We compare two configurations:\n",
    "\n",
    "1. **Cell image only (Cyto3)**: segments cells using cytoplasmic channels (e.g., AGP, ER).\n",
    "2. **Cell + Nuclei image (Cyto3 + DNA)**: provides the nuclei as auxiliary input to help refine cell boundaries.\n",
    "\n",
    "This comparison helps illustrate the benefit of multi-channel segmentation using Cellpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea34952-cff7-40a0-9a8c-77ae463afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined Cellpose parameters\n",
    "# For examples of parameter values visit https://forum.image.sc/t/cellpose-flow-and-cell-threshold/70347/4\n",
    "\n",
    "diameter = 45             # Approximate diameter of cells in pixels\n",
    "flow_threshold = 0.4      # Mask confidence cutoff (lower = more cells, more false positives)\n",
    "cellprob_threshold = 0    # Lower = more permissive to cell detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213b660-ff25-4234-9f05-b8af43f477ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load cell and nuclei images\n",
    "agp_image_path = Path(\"../data_day2-3/JUMP-CP_mini/Brefeldin-A-like/Orig/AGP/CP1-SC1-08_P06_T0001F001L01A04Z01C05.tif\")     # AGP or ER or both merged\n",
    "nuclei_image_path = Path(\"../data_day2-3/JUMP-CP_mini/Brefeldin-A-like/Orig/DNA/CP1-SC1-08_P06_T0001F001L01A01Z01C01.tif\") # DNA\n",
    "er_image_path = Path(\"../data_day2-3/JUMP-CP_mini/Brefeldin-A-like/Orig/ER/CP1-SC1-08_P06_T0001F001L01A03Z01C04.tif\") # ER\n",
    "\n",
    "agp_img = load_and_preprocess_mito_image(agp_image_path)\n",
    "nuclei_img = load_and_preprocess_mito_image(nuclei_image_path)\n",
    "er_img = load_and_preprocess_mito_image(er_image_path)\n",
    "\n",
    "# Normalize before stacking\n",
    "agp_img = rescale_intensity(agp_img, out_range=(0,1))\n",
    "nuclei_img = rescale_intensity(nuclei_img, out_range=(0,1))\n",
    "er_img = rescale_intensity(er_img, out_range=(0,1))\n",
    "\n",
    "# Stack images for Cellpose (2 channels)\n",
    "stacked_cell_img = np.stack([agp_img, er_img], axis=-1)\n",
    "stacked_img = np.stack([agp_img, er_img, nuclei_img], axis=-1)\n",
    "\n",
    "# Initialize model\n",
    "model = models.Cellpose(model_type=\"cyto3\", gpu=False)\n",
    "\n",
    "# Segmentation with cell channel only\n",
    "masks_cellonly, _, _, _ = model.eval(stacked_img,diameter=60,flow_threshold=2,cellprob_threshold=-6,channels=[0,0])\n",
    "\n",
    "# === Segmentation with cell + nuclei ===\n",
    "#masks_cellnuc, *_ = model.eval(stacked_img, channels=[1, 0])  # two-channel input\n",
    "masks_cellnuc, _, _, _ = model.eval(stacked_img,diameter=100,flow_threshold=2,cellprob_threshold=-4,channels=[0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652bcbe-e0ee-4a21-bd41-2b942e30ef6a",
   "metadata": {},
   "source": [
    "### Visualization of cellpose segmentaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeffdc6-c81c-48a6-abbf-b787ec175785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "# Composite image for display\n",
    "composite_img = np.stack([agp_img, er_img, np.zeros_like(agp_img)], axis=-1)\n",
    "\n",
    "# Prepare figure with 2 rows and 3 columns\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# ==== First row: Cellpose with AGP + ER only ====\n",
    "# Plot 1: Original\n",
    "axs[0, 0].imshow(composite_img)\n",
    "axs[0, 0].set_title(\"Original (AGP + ER)\")\n",
    "axs[0, 0].axis(\"off\")\n",
    "\n",
    "# Plot 2: Cellpose mask (AGP + ER only)\n",
    "axs[0, 1].imshow(label2rgb(masks_cellonly, bg_label=0))\n",
    "axs[0, 1].set_title(\"Segmentation (AGP + ER only)\")\n",
    "axs[0, 1].axis(\"off\")\n",
    "\n",
    "# Plot 3: Overlay\n",
    "boundaries1 = find_boundaries(masks_cellonly)\n",
    "overlay1 = composite_img.copy()\n",
    "overlay1[boundaries1] = [1, 0, 0]\n",
    "axs[0, 2].imshow(overlay1)\n",
    "axs[0, 2].set_title(\"Overlay (AGP + ER only)\")\n",
    "axs[0, 2].axis(\"off\")\n",
    "\n",
    "# ==== Second row: Cellpose with AGP + ER + DNA ====\n",
    "# Plot 4: Original\n",
    "axs[1, 0].imshow(composite_img)\n",
    "axs[1, 0].set_title(\"Original (AGP + ER)\")\n",
    "axs[1, 0].axis(\"off\")\n",
    "\n",
    "# Plot 5: Cellpose mask (AGP + ER + DNA)\n",
    "axs[1, 1].imshow(label2rgb(masks_cellnuc, bg_label=0))\n",
    "axs[1, 1].set_title(\"Segmentation (AGP + ER + DNA)\")\n",
    "axs[1, 1].axis(\"off\")\n",
    "\n",
    "# Plot 6: Overlay\n",
    "boundaries2 = find_boundaries(masks_cellnuc)\n",
    "overlay2 = composite_img.copy()\n",
    "overlay2[boundaries2] = [1, 0, 0]\n",
    "axs[1, 2].imshow(overlay2)\n",
    "axs[1, 2].set_title(\"Overlay (AGP + ER + DNA)\")\n",
    "axs[1, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec5ba7-6eb2-434e-b601-a947b8a9b455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
